name: Deploy WebApp to EKS Cluster

#on: [ workflow_dispatch ] 
on:
  push:
    branches: [ "testing_aws", "master" ]

env:
  AWS_REGION: ${{secrets.AWS_REGION}}
  ECR_REPOSITORY: webapp1-demo-shop
  ECR_REGISTRY: ${secrets.AWS_ACCOUNT_ID}.dkr.ecr.${secrets.AWS_REGION}.amazonaws.com"
  EKS_CLUSTER_NAME: webapps-demo
  CONTAINER_NAME: webapp1-demo-shop
  EKS_APP_NAME: webapp1-demo-shop
  EKS_SERVICE: webapp1
  EKS_SERVICE_ACCOUNT: webapp-sa1
  EKS_NAMESPACE: webapp
  EKS_DEPLOYMENT_NAME: webapp1-deployment
  APP_DIR: app1
  MANIFESTS_DIR: aws/eks/deploy/manifest/webapp1
  AWS_ACCOUNT_ID: ${{secrets.AWS_ACCOUNT_ID}}
  AWS_APP_PORT: "25443"
  GITHUB_SHA: ${{ github.sha }}
  IMAGE_NAME: ${{secrets.AWS_ACCOUNT_ID}}.dkr.ecr.${{secrets.AWS_REGION}}.amazonaws.com/webapp1-demo-shop:${{github.sha}}
  
jobs:
  Build:
    runs-on: ubuntu-latest
    outputs:
      image: ${{ steps.build-image.outputs.image }}

    steps:
      - name: Checkout
        uses: actions/checkout@v3

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}
          mask-aws-account-id: no

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v1

      - name: Build, tag, and push image to Amazon ECR
        id: build-image
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          IMAGE_TAG: ${{ env.GITHUB_SHA }}
        working-directory: ${{env.APP_DIR}}
        run: |
          imagename=$ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG
          echo "Build and push $imagename"
          docker build -t $imagename .
          docker push $imagename
          echo "image=$imagename" >> $GITHUB_OUTPUT
  
  #Image scan with Aqua Trivy     
  Scan:
    needs: [Build]
    runs-on: ubuntu-latest
    steps:
      - uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}
          mask-aws-account-id: no    
      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@master
        with:
          image-ref: '${{secrets.AWS_ACCOUNT_ID}}.dkr.ecr.${{secrets.AWS_REGION}}.amazonaws.com/webapp1-demo-shop:${{github.sha}}'
          format: 'table'
          #exit-code: '1' #By pass and continue if vulnerabilities found (Not recommended, testing complete devSecOps pipeline)
          ignore-unfixed: true
          vuln-type: 'os,library'
          severity: 'CRITICAL,HIGH'  

  Deploy:
    runs-on: ubuntu-latest
    environment: Staging
    needs: [Scan]

    steps:
      - name: Checkout
        uses: actions/checkout@v3

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v1
        env:
          KUBE_CONFIG_DATA: ${{ secrets.KUBE_CONFIG_DATA }}
          IMAGE_NAME: ${{env.ECR_REGISTRY}}/${{env.ECR_REPOSITORY}}:${{env.GITHUB_SHA}}
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}
      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v1
      
      #Configure kubectl
      - name: Configure kubectl
        run: |
          echo ${{ secrets.KUBE_CONFIG_DATA }} | base64 --decode > kubeconfig.yaml
          mkdir -p ~/.kube
          mv kubeconfig.yaml ~/.kube/config
      #Deploy application  
      - name: Deploy
        working-directory: ${{env.MANIFESTS_DIR}}
        run: |-
          envsubst < webapp1.yaml | kubectl apply -f -
          envsubst < Service.yaml | kubectl apply -f -
          envsubst < Deployment.yaml | kubectl apply -f -
          kubectl get pods -o wide -n ${{env.EKS_NAMESPACE}}
          kubectl get svc -o wide -n ${{env.EKS_NAMESPACE}}
          sleep 120
      
      #Check application is running, test REST endpoints
      - name: Verify Coontainer Application
        run: |-
          # kubectl rollout status deploy ${{env.EKS_APP_NAME}} -n ${{env.EKS_NAMESPACE}}
          curl -Lk https://`kubectl get svc -n ${{env.EKS_NAMESPACE}} | grep ${{env.EKS_SERVICE}} | awk '{print $4}'`:${{env.AWS_APP_PORT}}/backup/status 
          curl -Lk https://`kubectl get svc -n ${{env.EKS_NAMESPACE}} | grep ${{env.EKS_SERVICE}} | awk '{print $4}'`:${{env.AWS_APP_PORT}}/backup/create 
          curl -Lk https://`kubectl get svc -n ${{env.EKS_NAMESPACE}} | grep ${{env.EKS_SERVICE}} | awk '{print $4}'`:${{env.AWS_APP_PORT}}/backup/delete

      #Notify Slack
      - name: Notify Slack
        uses: ravsamhq/notify-slack-action@v2
        if: always()
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_CI_HOOK }}
        with:
          status: ${{ job.status }}
          notification_title: "{workflow}:{job} has {status_message}"
          message_format: "{emoji} *{workflow}:{job}* {status_message} in <{repo_url}|{repo}>"
          footer: "Logs <{run_url}|{job}>"
          notify_when: "failure,success"      
  
  zap_scan:
    runs-on: ubuntu-latest
    name: zap_scan
    needs: [Deploy]
    steps:
      - name: Checkout
        uses: actions/checkout@v2
        with:
          ref: master
      - name: ZAP Scan
        uses: zaproxy/action-baseline@v0.6.1
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          docker_name: 'owasp/zap2docker-stable'
          target: "https://a50ca0878c93c4885aa8a064120b93c1-237887041.us-east-1.elb.amazonaws.com:25443/backup/status"
          # target: ${{env.CREATE_EP}}
          rules_file_name: '.zap/rules.tsv'
          cmd_options: '-a'         
